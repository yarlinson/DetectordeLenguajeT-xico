# Generated by Django 5.2.7 on 2025-10-27 06:05

import django.db.models.deletion
import django.utils.timezone
from django.conf import settings
from django.db import migrations, models


class Migration(migrations.Migration):

    initial = True

    dependencies = [
        migrations.swappable_dependency(settings.AUTH_USER_MODEL),
    ]

    operations = [
        migrations.CreateModel(
            name='AnalysisStatistics',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('date', models.DateField(help_text='Fecha de las estadísticas', unique=True, verbose_name='Fecha')),
                ('total_analyses', models.PositiveIntegerField(default=0, help_text='Número total de análisis realizados en esta fecha', verbose_name='Total de análisis')),
                ('toxic_analyses', models.PositiveIntegerField(default=0, help_text='Número de análisis que detectaron toxicidad', verbose_name='Análisis tóxicos')),
                ('safe_analyses', models.PositiveIntegerField(default=0, help_text='Número de análisis que no detectaron toxicidad', verbose_name='Análisis seguros')),
                ('low_toxicity', models.PositiveIntegerField(default=0, verbose_name='Toxicidad baja')),
                ('medium_toxicity', models.PositiveIntegerField(default=0, verbose_name='Toxicidad media')),
                ('high_toxicity', models.PositiveIntegerField(default=0, verbose_name='Toxicidad alta')),
                ('extreme_toxicity', models.PositiveIntegerField(default=0, verbose_name='Toxicidad extrema')),
                ('insults_count', models.PositiveIntegerField(default=0, verbose_name='Insultos detectados')),
                ('threats_count', models.PositiveIntegerField(default=0, verbose_name='Amenazas detectadas')),
                ('hate_count', models.PositiveIntegerField(default=0, verbose_name='Odio detectado')),
                ('harassment_count', models.PositiveIntegerField(default=0, verbose_name='Acoso detectado')),
                ('profanity_count', models.PositiveIntegerField(default=0, verbose_name='Profanidad detectada')),
                ('created_at', models.DateTimeField(default=django.utils.timezone.now, verbose_name='Fecha de creación')),
                ('updated_at', models.DateTimeField(auto_now=True, verbose_name='Fecha de actualización')),
            ],
            options={
                'verbose_name': 'Estadística de Análisis',
                'verbose_name_plural': 'Estadísticas de Análisis',
                'ordering': ['-date'],
            },
        ),
        migrations.CreateModel(
            name='ToxicPattern',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('name', models.CharField(help_text='Nombre descriptivo del patrón', max_length=100, verbose_name='Nombre del patrón')),
                ('pattern', models.TextField(help_text='Expresión regular que define el patrón tóxico', verbose_name='Patrón regex')),
                ('toxicity_type', models.CharField(choices=[('insult', 'Insult'), ('threat', 'Threat'), ('hate', 'Hate'), ('harassment', 'Harassment'), ('profanity', 'Profanity')], help_text='Tipo de toxicidad que detecta este patrón', max_length=20, verbose_name='Tipo de toxicidad')),
                ('toxicity_level', models.CharField(choices=[('safe', 'Safe'), ('low', 'Low'), ('medium', 'Medium'), ('high', 'High'), ('extreme', 'Extreme')], default='low', help_text='Nivel de toxicidad asignado a este patrón', max_length=20, verbose_name='Nivel de toxicidad')),
                ('description', models.TextField(blank=True, help_text='Descripción detallada del patrón', verbose_name='Descripción')),
                ('is_active', models.BooleanField(default=True, help_text='Indica si el patrón está activo en el detector', verbose_name='Activo')),
                ('created_at', models.DateTimeField(default=django.utils.timezone.now, verbose_name='Fecha de creación')),
                ('updated_at', models.DateTimeField(auto_now=True, verbose_name='Fecha de actualización')),
            ],
            options={
                'verbose_name': 'Patrón Tóxico',
                'verbose_name_plural': 'Patrones Tóxicos',
                'ordering': ['-created_at'],
            },
        ),
        migrations.CreateModel(
            name='TextAnalysis',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('text', models.TextField(help_text='El texto que fue analizado por el detector', verbose_name='Texto analizado')),
                ('is_toxic', models.BooleanField(default=False, help_text='Indica si el texto contiene contenido tóxico', verbose_name='Es tóxico')),
                ('toxicity_level', models.CharField(choices=[('safe', 'Safe'), ('low', 'Low'), ('medium', 'Medium'), ('high', 'High'), ('extreme', 'Extreme')], default='safe', help_text='Nivel de toxicidad detectado', max_length=20, verbose_name='Nivel de toxicidad')),
                ('toxicity_types', models.JSONField(default=list, help_text='Lista de tipos de toxicidad detectados', verbose_name='Tipos de toxicidad')),
                ('matched_patterns', models.JSONField(default=list, help_text='Patrones regex que coincidieron con el texto', verbose_name='Patrones encontrados')),
                ('confidence', models.FloatField(default=0.0, help_text='Nivel de confianza del análisis (0.0 a 1.0)', verbose_name='Confianza')),
                ('ip_address', models.GenericIPAddressField(blank=True, help_text='IP desde la cual se realizó el análisis', null=True, verbose_name='Dirección IP')),
                ('user_agent', models.TextField(blank=True, help_text='Información del navegador del usuario', verbose_name='User Agent')),
                ('created_at', models.DateTimeField(default=django.utils.timezone.now, help_text='Fecha y hora cuando se realizó el análisis', verbose_name='Fecha de creación')),
                ('user', models.ForeignKey(blank=True, help_text='Usuario que realizó el análisis', null=True, on_delete=django.db.models.deletion.CASCADE, to=settings.AUTH_USER_MODEL, verbose_name='Usuario')),
            ],
            options={
                'verbose_name': 'Análisis de Texto',
                'verbose_name_plural': 'Análisis de Textos',
                'ordering': ['-created_at'],
                'indexes': [models.Index(fields=['is_toxic'], name='detector_te_is_toxi_61241e_idx'), models.Index(fields=['toxicity_level'], name='detector_te_toxicit_4d043e_idx'), models.Index(fields=['created_at'], name='detector_te_created_764f6c_idx')],
            },
        ),
    ]
